The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  2.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.07s/it]
