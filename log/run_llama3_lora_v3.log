06/19/2024 13:55:43 - WARNING - decoder_lora.log - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
06/19/2024 13:55:44 - INFO - decoder_lora.log - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=True,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=18000000,
debug=[],
deepspeed=None,
disable_tqdm=True,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=100,
evaluation_strategy=steps,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=8,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=True,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./output/v3/llama3/logs,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_torch,
optim_args=None,
output_dir=./output/v3/llama3,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./output/v3/llama3,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=100,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=400,
weight_decay=0.0,
)
/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:1096: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-06-19 13:55:44,000 >> loading configuration file ../model/pretrained/Meta-Llama-3-8B-Instruct/config.json
[INFO|configuration_utils.py:791] 2024-06-19 13:55:44,001 >> Model config LlamaConfig {
  "_name_or_path": "../model/pretrained/Meta-Llama-3-8B-Instruct",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128009,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.2",
  "use_cache": true,
  "vocab_size": 128256
}

/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:720: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
[INFO|tokenization_utils_base.py:2044] 2024-06-19 13:55:44,002 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2044] 2024-06-19 13:55:44,002 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2044] 2024-06-19 13:55:44,002 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2044] 2024-06-19 13:55:44,002 >> loading file tokenizer_config.json
[WARNING|logging.py:314] 2024-06-19 13:55:44,183 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
<|eot_id|>
06/19/2024 13:55:44 - INFO - decoder_lora.log - lora配置: LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules={'o_proj', 'q_proj', 'v_proj', 'up_proj', 'down_proj', 'gate_proj', 'k_proj'}, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False)
06/19/2024 13:55:44 - INFO - decoder_lora.log - torch_dtype: torch.float16
/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
[INFO|modeling_utils.py:3254] 2024-06-19 13:55:44,191 >> loading weights file ../model/pretrained/Meta-Llama-3-8B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:1400] 2024-06-19 13:55:44,191 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[WARNING|logging.py:329] 2024-06-19 13:55:44,191 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[INFO|configuration_utils.py:845] 2024-06-19 13:55:44,193 >> Generate config GenerationConfig {
  "bos_token_id": 128000,
  "eos_token_id": 128009
}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.30s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.17it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]
[INFO|modeling_utils.py:3992] 2024-06-19 13:55:48,574 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4000] 2024-06-19 13:55:48,574 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at ../model/pretrained/Meta-Llama-3-8B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:798] 2024-06-19 13:55:48,576 >> loading configuration file ../model/pretrained/Meta-Llama-3-8B-Instruct/generation_config.json
[INFO|configuration_utils.py:845] 2024-06-19 13:55:48,577 >> Generate config GenerationConfig {
  "bos_token_id": 128000,
  "do_sample": true,
  "eos_token_id": [
    128001,
    128009
  ],
  "max_length": 4096,
  "temperature": 0.6,
  "top_p": 0.9
}

/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Using custom data configuration default-8029bada6b05a0ca
trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.26047588741133265
06/19/2024 13:55:50 - INFO - datasets.builder - Using custom data configuration default-8029bada6b05a0ca
Loading Dataset Infos from /home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/datasets/packaged_modules/csv
06/19/2024 13:55:50 - INFO - datasets.info - Loading Dataset Infos from /home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/datasets/packaged_modules/csv
Overwrite dataset info from restored data version if exists.
06/19/2024 13:55:50 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from ./output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6
06/19/2024 13:55:50 - INFO - datasets.info - Loading Dataset info from ./output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6
Found cached dataset csv (/home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6)
06/19/2024 13:55:50 - INFO - datasets.builder - Found cached dataset csv (/home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6)
Loading Dataset info from /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6
06/19/2024 13:55:50 - INFO - datasets.info - Loading Dataset info from /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6
Process #0 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00000_of_00010.arrow
数据集中是否输入输出在同一列: True
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #0 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00000_of_00010.arrow
Process #1 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00001_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #1 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00001_of_00010.arrow
Process #2 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00002_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #2 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00002_of_00010.arrow
Process #3 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00003_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #3 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00003_of_00010.arrow
Process #4 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00004_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #4 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00004_of_00010.arrow
Process #5 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00005_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #5 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00005_of_00010.arrow
Process #6 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00006_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #6 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00006_of_00010.arrow
Process #7 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00007_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #7 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00007_of_00010.arrow
Process #8 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00008_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #8 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00008_of_00010.arrow
Process #9 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00009_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #9 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_00009_of_00010.arrow
Loading cached processed dataset at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_*_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-468bec77b8e5819d_*_of_00010.arrow
Concatenating 10 shards
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Process #0 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00000_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #0 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00000_of_00010.arrow
Process #1 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00001_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #1 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00001_of_00010.arrow
Process #2 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00002_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #2 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00002_of_00010.arrow
Process #3 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00003_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #3 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00003_of_00010.arrow
Process #4 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00004_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #4 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00004_of_00010.arrow
Process #5 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00005_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #5 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00005_of_00010.arrow
Process #6 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00006_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #6 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00006_of_00010.arrow
Process #7 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00007_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #7 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00007_of_00010.arrow
Process #8 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00008_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #8 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00008_of_00010.arrow
Process #9 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00009_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Process #9 will write at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_00009_of_00010.arrow
Loading cached processed dataset at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_*_of_00010.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-7db49721cb0cded4_*_of_00010.arrow
Concatenating 10 shards
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Concatenating 10 shards
06/19/2024 13:55:50 - INFO - decoder_lora.log - 训练集的采样114: {'input_ids': [128000, 128000, 128006, 9125, 128007, 271, 57668, 122503, 114734, 107015, 124177, 9554, 96511, 46729, 1811, 90112, 20834, 15120, 40089, 75486, 47548, 39045, 57668, 116602, 18655, 92019, 9554, 75486, 47548, 122548, 64026, 41127, 40862, 13153, 49, 75486, 47548, 9554, 115707, 119464, 41127, 40862, 121964, 49, 75486, 47548, 48706, 110158, 104584, 96153, 45163, 42246, 17620, 13153, 43240, 40089, 16937, 110158, 104584, 9554, 49, 75486, 47548, 1811, 128009, 128006, 882, 128007, 271, 75486, 47548, 25, 37689, 70141, 102782, 43378, 16937, 105005, 106529, 13153, 39209, 65659, 33052, 3922, 37689, 70141, 102782, 43378, 64467, 103507, 74770, 125844, 92553, 1811, 128009, 128006, 78191, 128007, 271, 13233, 220, 16, 198, 333, 220, 102782, 43378, 33005, 374, 123038, 70141, 102782, 43378, 198, 3473, 6704, 37648, 374, 87109, 105005, 106529, 323, 6704, 37648, 105494, 374, 87646, 39209, 65659, 33052, 198, 13233, 220, 17, 198, 333, 6704, 37648, 105494, 374, 123038, 70141, 102782, 43378, 64467, 103507, 198, 3473, 6704, 37648, 374, 118807, 97, 92553, 128009, 128001], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [128000, 128000, 128006, 9125, 128007, 271, 57668, 122503, 114734, 107015, 124177, 9554, 96511, 46729, 1811, 90112, 20834, 15120, 40089, 75486, 47548, 39045, 57668, 116602, 18655, 92019, 9554, 75486, 47548, 122548, 64026, 41127, 40862, 13153, 49, 75486, 47548, 9554, 115707, 119464, 41127, 40862, 121964, 49, 75486, 47548, 48706, 110158, 104584, 96153, 45163, 42246, 17620, 13153, 43240, 40089, 16937, 110158, 104584, 9554, 49, 75486, 47548, 1811, 128009, 128006, 882, 128007, 271, 75486, 47548, 25, 37689, 70141, 102782, 43378, 16937, 105005, 106529, 13153, 39209, 65659, 33052, 3922, 37689, 70141, 102782, 43378, 64467, 103507, 74770, 125844, 92553, 1811, 128009, 128006, 78191, 128007, 271, 13233, 220, 16, 198, 333, 220, 102782, 43378, 33005, 374, 123038, 70141, 102782, 43378, 198, 3473, 6704, 37648, 374, 87109, 105005, 106529, 323, 6704, 37648, 105494, 374, 87646, 39209, 65659, 33052, 198, 13233, 220, 17, 198, 333, 6704, 37648, 105494, 374, 123038, 70141, 102782, 43378, 64467, 103507, 198, 3473, 6704, 37648, 374, 118807, 97, 92553, 128009, 128001]}
Loading cached shuffled indices for dataset at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-ebe5ec4a5505bfb1.arrow
06/19/2024 13:55:50 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/asus/intelligent-test/decoder_lora/output/v3/llama3/dataset_cache/csv/default-8029bada6b05a0ca/0.0.0/2c2bba169a7e870eb2bcc07f2c69b72b171db4933b1c2e2833d2b48aeaf2f6c6/cache-ebe5ec4a5505bfb1.arrow
/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
[INFO|trainer.py:601] 2024-06-19 13:55:50,337 >> Using auto half precision backend
[INFO|trainer.py:1812] 2024-06-19 13:55:50,562 >> ***** Running training *****
[INFO|trainer.py:1813] 2024-06-19 13:55:50,562 >>   Num examples = 575
[INFO|trainer.py:1814] 2024-06-19 13:55:50,562 >>   Num Epochs = 10
[INFO|trainer.py:1815] 2024-06-19 13:55:50,562 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1818] 2024-06-19 13:55:50,562 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1819] 2024-06-19 13:55:50,562 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1820] 2024-06-19 13:55:50,562 >>   Total optimization steps = 710
[INFO|trainer.py:1821] 2024-06-19 13:55:50,565 >>   Number of trainable parameters = 20,971,520
[WARNING|logging.py:329] 2024-06-19 13:55:50,579 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[WARNING|logging.py:329] 2024-06-19 13:55:50,822 >> The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.
