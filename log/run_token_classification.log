/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.5)
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
Some weights of the model checkpoint at ../model/mengzi-bert-base-fin were not used when initializing BertForTokenClassification: ['pos_transform.LayerNorm.bias', 'pos_transform.LayerNorm.weight', 'sop.cls.weight', 'pos_transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'pos_head.bias', 'pos_head.weight', 'pos_transform.dense.weight', 'sop.cls.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at ../model/mengzi-bert-base-fin and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/asus/miniconda3/envs/intelligent-test/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
{'loss': 0.8842, 'learning_rate': 2e-05, 'epoch': 0.02}
{'loss': 0.4816, 'learning_rate': 2e-05, 'epoch': 0.04}
{'loss': 0.4052, 'learning_rate': 2e-05, 'epoch': 0.06}
{'loss': 0.3912, 'learning_rate': 2e-05, 'epoch': 0.08}
{'loss': 0.3424, 'learning_rate': 2e-05, 'epoch': 0.1}
{'loss': 0.3006, 'learning_rate': 2e-05, 'epoch': 0.12}
{'loss': 0.3004, 'learning_rate': 2e-05, 'epoch': 0.14}
{'loss': 0.2906, 'learning_rate': 2e-05, 'epoch': 0.16}
{'loss': 0.302, 'learning_rate': 2e-05, 'epoch': 0.17}
{'loss': 0.2804, 'learning_rate': 2e-05, 'epoch': 0.19}
{'loss': 0.2672, 'learning_rate': 2e-05, 'epoch': 0.21}
{'loss': 0.2825, 'learning_rate': 2e-05, 'epoch': 0.23}
{'loss': 0.2486, 'learning_rate': 2e-05, 'epoch': 0.25}
{'loss': 0.2458, 'learning_rate': 2e-05, 'epoch': 0.27}
{'loss': 0.272, 'learning_rate': 2e-05, 'epoch': 0.29}
{'loss': 0.2208, 'learning_rate': 2e-05, 'epoch': 0.31}
{'loss': 0.2353, 'learning_rate': 2e-05, 'epoch': 0.33}
{'loss': 0.2148, 'learning_rate': 2e-05, 'epoch': 0.35}
{'loss': 0.2244, 'learning_rate': 2e-05, 'epoch': 0.37}
{'loss': 0.2242, 'learning_rate': 2e-05, 'epoch': 0.39}
{'loss': 0.2222, 'learning_rate': 2e-05, 'epoch': 0.41}
{'loss': 0.215, 'learning_rate': 2e-05, 'epoch': 0.43}
{'loss': 0.2164, 'learning_rate': 2e-05, 'epoch': 0.45}
{'loss': 0.2143, 'learning_rate': 2e-05, 'epoch': 0.47}
{'loss': 0.204, 'learning_rate': 2e-05, 'epoch': 0.49}
{'loss': 0.1897, 'learning_rate': 2e-05, 'epoch': 0.5}
{'loss': 0.1863, 'learning_rate': 2e-05, 'epoch': 0.52}
{'loss': 0.2072, 'learning_rate': 2e-05, 'epoch': 0.54}
{'loss': 0.2022, 'learning_rate': 2e-05, 'epoch': 0.56}
{'loss': 0.1741, 'learning_rate': 2e-05, 'epoch': 0.58}
{'loss': 0.1792, 'learning_rate': 2e-05, 'epoch': 0.6}
{'loss': 0.1827, 'learning_rate': 2e-05, 'epoch': 0.62}
{'loss': 0.1808, 'learning_rate': 2e-05, 'epoch': 0.64}
{'loss': 0.1795, 'learning_rate': 2e-05, 'epoch': 0.66}
{'loss': 0.1709, 'learning_rate': 2e-05, 'epoch': 0.68}
{'loss': 0.1691, 'learning_rate': 2e-05, 'epoch': 0.7}
{'loss': 0.1706, 'learning_rate': 2e-05, 'epoch': 0.72}
{'loss': 0.1755, 'learning_rate': 2e-05, 'epoch': 0.74}
{'loss': 0.1742, 'learning_rate': 2e-05, 'epoch': 0.76}
{'loss': 0.1703, 'learning_rate': 2e-05, 'epoch': 0.78}
{'loss': 0.1472, 'learning_rate': 2e-05, 'epoch': 0.8}
{'loss': 0.1723, 'learning_rate': 2e-05, 'epoch': 0.82}
{'loss': 0.1617, 'learning_rate': 2e-05, 'epoch': 0.83}
{'loss': 0.1562, 'learning_rate': 2e-05, 'epoch': 0.85}
{'loss': 0.1481, 'learning_rate': 2e-05, 'epoch': 0.87}
{'loss': 0.1437, 'learning_rate': 2e-05, 'epoch': 0.89}
{'loss': 0.1685, 'learning_rate': 2e-05, 'epoch': 0.91}
{'loss': 0.1443, 'learning_rate': 2e-05, 'epoch': 0.93}
{'loss': 0.1546, 'learning_rate': 2e-05, 'epoch': 0.95}
{'loss': 0.1369, 'learning_rate': 2e-05, 'epoch': 0.97}
{'loss': 0.1449, 'learning_rate': 2e-05, 'epoch': 0.99}
{'eval_loss': 0.07604808360338211, 'eval_runtime': 4.52, 'eval_samples_per_second': 141.151, 'eval_steps_per_second': 17.699, 'epoch': 1.0}
{'loss': 0.1488, 'learning_rate': 2e-05, 'epoch': 1.01}
{'loss': 0.1433, 'learning_rate': 2e-05, 'epoch': 1.03}
{'loss': 0.1237, 'learning_rate': 2e-05, 'epoch': 1.05}
{'loss': 0.1301, 'learning_rate': 2e-05, 'epoch': 1.07}
{'loss': 0.1378, 'learning_rate': 2e-05, 'epoch': 1.09}
{'loss': 0.1311, 'learning_rate': 2e-05, 'epoch': 1.11}
{'loss': 0.1129, 'learning_rate': 2e-05, 'epoch': 1.13}
{'loss': 0.1169, 'learning_rate': 2e-05, 'epoch': 1.15}
{'loss': 0.1236, 'learning_rate': 2e-05, 'epoch': 1.16}
{'loss': 0.1017, 'learning_rate': 2e-05, 'epoch': 1.18}
{'loss': 0.1279, 'learning_rate': 2e-05, 'epoch': 1.2}
{'loss': 0.128, 'learning_rate': 2e-05, 'epoch': 1.22}
{'loss': 0.1039, 'learning_rate': 2e-05, 'epoch': 1.24}
{'loss': 0.1273, 'learning_rate': 2e-05, 'epoch': 1.26}
{'loss': 0.1095, 'learning_rate': 2e-05, 'epoch': 1.28}
{'loss': 0.1263, 'learning_rate': 2e-05, 'epoch': 1.3}
{'loss': 0.1286, 'learning_rate': 2e-05, 'epoch': 1.32}
{'loss': 0.13, 'learning_rate': 2e-05, 'epoch': 1.34}
{'loss': 0.1151, 'learning_rate': 2e-05, 'epoch': 1.36}
{'loss': 0.1226, 'learning_rate': 2e-05, 'epoch': 1.38}
{'loss': 0.125, 'learning_rate': 2e-05, 'epoch': 1.4}
{'loss': 0.1063, 'learning_rate': 2e-05, 'epoch': 1.42}
{'loss': 0.116, 'learning_rate': 2e-05, 'epoch': 1.44}
{'loss': 0.1079, 'learning_rate': 2e-05, 'epoch': 1.46}
{'loss': 0.1181, 'learning_rate': 2e-05, 'epoch': 1.48}
{'loss': 0.1034, 'learning_rate': 2e-05, 'epoch': 1.49}
{'loss': 0.1157, 'learning_rate': 2e-05, 'epoch': 1.51}
{'loss': 0.1207, 'learning_rate': 2e-05, 'epoch': 1.53}
{'loss': 0.1126, 'learning_rate': 2e-05, 'epoch': 1.55}
{'loss': 0.117, 'learning_rate': 2e-05, 'epoch': 1.57}
{'loss': 0.1188, 'learning_rate': 2e-05, 'epoch': 1.59}
{'loss': 0.1014, 'learning_rate': 2e-05, 'epoch': 1.61}
{'loss': 0.0981, 'learning_rate': 2e-05, 'epoch': 1.63}
{'loss': 0.1101, 'learning_rate': 2e-05, 'epoch': 1.65}
{'loss': 0.1203, 'learning_rate': 2e-05, 'epoch': 1.67}
{'loss': 0.1043, 'learning_rate': 2e-05, 'epoch': 1.69}
{'loss': 0.1084, 'learning_rate': 2e-05, 'epoch': 1.71}
{'loss': 0.1125, 'learning_rate': 2e-05, 'epoch': 1.73}
{'loss': 0.1013, 'learning_rate': 2e-05, 'epoch': 1.75}
{'loss': 0.0951, 'learning_rate': 2e-05, 'epoch': 1.77}
{'loss': 0.1092, 'learning_rate': 2e-05, 'epoch': 1.79}
{'loss': 0.1127, 'learning_rate': 2e-05, 'epoch': 1.81}
{'loss': 0.0984, 'learning_rate': 2e-05, 'epoch': 1.82}
{'loss': 0.109, 'learning_rate': 2e-05, 'epoch': 1.84}
{'loss': 0.0998, 'learning_rate': 2e-05, 'epoch': 1.86}
{'loss': 0.1054, 'learning_rate': 2e-05, 'epoch': 1.88}
{'loss': 0.1001, 'learning_rate': 2e-05, 'epoch': 1.9}
{'loss': 0.1096, 'learning_rate': 2e-05, 'epoch': 1.92}
{'loss': 0.1015, 'learning_rate': 2e-05, 'epoch': 1.94}
{'loss': 0.1152, 'learning_rate': 2e-05, 'epoch': 1.96}
{'loss': 0.1067, 'learning_rate': 2e-05, 'epoch': 1.98}
{'loss': 0.1154, 'learning_rate': 2e-05, 'epoch': 2.0}
{'eval_loss': 0.06508826464414597, 'eval_runtime': 4.5277, 'eval_samples_per_second': 140.91, 'eval_steps_per_second': 17.669, 'epoch': 2.0}
{'loss': 0.0795, 'learning_rate': 2e-05, 'epoch': 2.02}
{'loss': 0.0981, 'learning_rate': 2e-05, 'epoch': 2.04}
{'loss': 0.0972, 'learning_rate': 2e-05, 'epoch': 2.06}
{'loss': 0.083, 'learning_rate': 2e-05, 'epoch': 2.08}
{'loss': 0.0976, 'learning_rate': 2e-05, 'epoch': 2.1}
{'loss': 0.0809, 'learning_rate': 2e-05, 'epoch': 2.12}
{'loss': 0.0818, 'learning_rate': 2e-05, 'epoch': 2.14}
{'loss': 0.075, 'learning_rate': 2e-05, 'epoch': 2.15}
{'loss': 0.0941, 'learning_rate': 2e-05, 'epoch': 2.17}
{'loss': 0.0745, 'learning_rate': 2e-05, 'epoch': 2.19}
{'loss': 0.1002, 'learning_rate': 2e-05, 'epoch': 2.21}
{'loss': 0.0808, 'learning_rate': 2e-05, 'epoch': 2.23}
{'loss': 0.1047, 'learning_rate': 2e-05, 'epoch': 2.25}
{'loss': 0.0881, 'learning_rate': 2e-05, 'epoch': 2.27}
{'loss': 0.0849, 'learning_rate': 2e-05, 'epoch': 2.29}
{'loss': 0.0885, 'learning_rate': 2e-05, 'epoch': 2.31}
{'loss': 0.0887, 'learning_rate': 2e-05, 'epoch': 2.33}
{'loss': 0.0714, 'learning_rate': 2e-05, 'epoch': 2.35}
{'loss': 0.09, 'learning_rate': 2e-05, 'epoch': 2.37}
{'loss': 0.1058, 'learning_rate': 2e-05, 'epoch': 2.39}
{'loss': 0.0765, 'learning_rate': 2e-05, 'epoch': 2.41}
{'loss': 0.0991, 'learning_rate': 2e-05, 'epoch': 2.43}
{'loss': 0.077, 'learning_rate': 2e-05, 'epoch': 2.45}
{'loss': 0.0879, 'learning_rate': 2e-05, 'epoch': 2.47}
{'loss': 0.093, 'learning_rate': 2e-05, 'epoch': 2.48}
{'loss': 0.0827, 'learning_rate': 2e-05, 'epoch': 2.5}
{'loss': 0.0906, 'learning_rate': 2e-05, 'epoch': 2.52}
{'loss': 0.0817, 'learning_rate': 2e-05, 'epoch': 2.54}
{'loss': 0.0861, 'learning_rate': 2e-05, 'epoch': 2.56}
{'loss': 0.0887, 'learning_rate': 2e-05, 'epoch': 2.58}
{'loss': 0.0706, 'learning_rate': 2e-05, 'epoch': 2.6}
{'loss': 0.0911, 'learning_rate': 2e-05, 'epoch': 2.62}
{'loss': 0.0812, 'learning_rate': 2e-05, 'epoch': 2.64}
{'loss': 0.0935, 'learning_rate': 2e-05, 'epoch': 2.66}
{'loss': 0.0806, 'learning_rate': 2e-05, 'epoch': 2.68}
{'loss': 0.0807, 'learning_rate': 2e-05, 'epoch': 2.7}
{'loss': 0.0712, 'learning_rate': 2e-05, 'epoch': 2.72}
{'loss': 0.0862, 'learning_rate': 2e-05, 'epoch': 2.74}
{'loss': 0.0894, 'learning_rate': 2e-05, 'epoch': 2.76}
{'loss': 0.073, 'learning_rate': 2e-05, 'epoch': 2.78}
{'loss': 0.0909, 'learning_rate': 2e-05, 'epoch': 2.8}
{'loss': 0.0848, 'learning_rate': 2e-05, 'epoch': 2.81}
{'loss': 0.0876, 'learning_rate': 2e-05, 'epoch': 2.83}
{'loss': 0.0749, 'learning_rate': 2e-05, 'epoch': 2.85}
{'loss': 0.0775, 'learning_rate': 2e-05, 'epoch': 2.87}
{'loss': 0.0876, 'learning_rate': 2e-05, 'epoch': 2.89}
{'loss': 0.0745, 'learning_rate': 2e-05, 'epoch': 2.91}
{'loss': 0.0907, 'learning_rate': 2e-05, 'epoch': 2.93}
{'loss': 0.0798, 'learning_rate': 2e-05, 'epoch': 2.95}
{'loss': 0.0816, 'learning_rate': 2e-05, 'epoch': 2.97}
{'loss': 0.0792, 'learning_rate': 2e-05, 'epoch': 2.99}
{'eval_loss': 0.053759392350912094, 'eval_runtime': 4.5352, 'eval_samples_per_second': 140.676, 'eval_steps_per_second': 17.64, 'epoch': 3.0}
